<article>
  <type>blog</type>
  <title>All-Knowing Eye Closes In on Reality</title>
  <author>Beverly Schaeffer</author>
  <date>May 27, 2011</date>
  <departments>
  </departments>
  <tags>
    <tag>Broad Area Announcement</tag>
    <tag>DARPA</tag>
    <tag>Mind's Eye Program</tag>
    <tag>smart camera</tag>
    <tag>U.S. Army Research Laboratory</tag>
    <tag>unmanned ground vehicles</tag>
    <tag>unmanned intelligent surveillance</tag>
    <tag>visual intelligence</tag>
    <tag>SIGNAL Magazine</tag>
  </tags>
  <abstract>Seeing is believing, but when a special surveillance camera is doing the watching, it's also interpreting and reporting what it views-and learning from it-without human intervention.</abstract>
  <text>Analysts and warfighters may not have to sift through reams of footage from a stationary surveillance system if the camera itself is programmed to determine exactly what's happening within its view. Maryann Lawlor's article, "Seeing Eye Systems Learn to Discern," in this issue of SIGNAL Magazine, describes the Mind's Eye program, a visual intelligence project underway at the Defense Advanced Research Projects Agency (DARPA) in cooperation with the U.S. Army Research Laboratory, industry and academia. The program focuses on creating the ability to enable a surveillance system to discern 48 verbs. The system also must be able to distinguish among different meanings of a specific verb as in "give a speech" and "give a gift." Once these lessons are "learned," a "smart camera" can be mounted on a pole or unmanned ground vehicle to provide intelligent persistent surveillance. Deployed troops face the dangers of covert enemy ops and other activities. This technology could be crucial to information sharing and to the safety it helps ensure. Humans won't be out of the loop; they'll instead be fortified with extra intel from these smart systems. The Broad Area Announcement (BAA) distinguishes machine-based visual intelligence with its focus on recognizing and reasoning with action as well as objects in video. The machines must visualize and manipulate scenes and use these concepts in an imaginative process. A platform equipped with a capability that mimics the human mind will not only be able to sound an alarm when it sees a familiar pattern-it'll anticipate what might happen next, imagine alternative futures, fill in the gaps and identify activity that doesn't fit the norm. The program began in September 2010. Fifteen research teams, called principal investigators (PIs), were awarded funding in January 2011. Lt. Col. James Donlon, USA, DARPA's Mind's Eye program manager, is pleased with the success thus far:

	These teams are responding very aggressively to this new challenge of addressing a much broader range of abilities and a broader range of activities. They're demonstrating some excellent initial progress in recognizing the 48 verbs in the BAA. So I'm expecting significant progress by the end of this first year.
The Mind's Eye team isn't just concerned with comparing machine performance to an objective of perfectly correct performance, but on comparing that to average human performance on the same tasks given the same inputs. The colonel notes that good works already are underway among the different organizations toward pairing smart cameras with platforms. These efforts will benefit the warfighter andÂ could have vital applications in other arenas as well. Read the full article for information on participating organizations, their contributions and their expectations. Do you see these technologies coming to fruition as anticipated? Share you opinions and ideas here.</text>
  <imgalttext>
  </imgalttext>
</article>
