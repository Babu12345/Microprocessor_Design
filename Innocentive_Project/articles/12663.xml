<article>
  <type>article</type>
  <title>Robots Learn With Heads in the Cloud</title>
  <author>George I. Seffers</author>
  <date>May 1, 2014</date>
  <departments>
    <department>Defense Operations</department>
    <department>Education</department>
    <department>International</department>
  </departments>
  <tags>
    <tag>cloud computing</tag>
    <tag>homeland defense</tag>
    <tag>research and development</tag>
    <tag>Robotics</tag>
    <tag>unmanned systems</tag>
    <tag>May 2014</tag>
  </tags>
  <abstract></abstract>
  <text>Researchers working on multiple projects in Europe and the United States are using cloud computing to teach robotic systems to perform a multitude of tasks ranging from household chores to serving hospital patients and flipping pancakes. The research, which one day could be applied to robotic systems used for national defense, homeland security or medical uses, lowers costs while allowing robots to learn more quickly, share information and better cooperate with one another.
Cloud robotics is an emerging research field rooted in cloud computing, cloud storage and other technologies centered around the benefits of converged infrastructure and shared services, according to researchers with the recently completed RoboEarth project, which was funded primarily by the European Commission. Cloud robotics allows robots to benefit from the powerful computational, storage and communications resources of modern data centers. In addition, it lowers costs for maintenance and updates and reduces dependence on custom middleware.
	Researchers with the RoboEarth project envision an Internet for robots that will allow systems to share information and learn from each other about their behavior and their environment, paving the way for rapid advances in machine cognition and behavior and, ultimately, for more subtle and sophisticated human-machine interaction.
	“The ultimate goal is to have an Internet for robots,” explains Gajamohan Mohanarajah, a graduate student with the Swiss Federal Institute of Technology. Mohanarajah has worked with RoboEarth almost from the project’s beginning in 2009 and gave a Technology, Entertainment and Design (TEDx) talk discussing how it works. “It’s not going to begin as an open Internet. It will be typically companies having their own networks because it is quite a security risk to open up all of the data and the access to robots. A big company maybe has its own network and its own robots connected to it. They will have their own ecosystem.” He points out the Internet began as a private network within the U.S. Defense Department.
	Mohanarajah reports in his TEDx talk that current cutting-edge service robotic systems can be outwitted by a 5-year-old; are slow-moving; see poorly while outdoors; and can cost as much as five high-end sport utility vehicles. Mohanarajah compares the life of a robot to living alone in a cave and having only a short-term memory.
Funding for the RoboEarth project officially ended in December 2013, and the researchers received an extension to conduct the final demonstration in January. That demonstration involved multiple robots cooperating to serve a drink to a hospital patient. One robot equipped with the proper sensors entered the room and mapped it out. That mapping information was uploaded to the cloud, where others were able to download it and immediately know how to maneuver around the room. A robotic arm placed the drink on a tray being carried by another robot, which then delivered it to the patient. “This showed that the cloud is used not only as a computation and storage medium but also as a communication medium so that they can perform collaborative tasks,” Mohanarajah offers.
	The RoboEarth project demonstrated that robotic systems can use the cloud to learn, share information and cooperate. Also, it identified remaining challenges, including a limited language for robots and storage scalability issues, Mohanarajah reports. He adds that the technology works best with systems that are alike. “With a humanoid robot and a robot that looks like a cheetah, for example, there are only a few things they can learn from each other, especially when it comes to physical motions. If you have a big common denominator, then the advantage of using RoboEarth would be more,” he states.
	He describes RoboEarth as the first project of its kind and says that although it has ended, researchers have identified areas of individual interest and will continue working independently. The software is open source and available for anyone to use. “It’s not production-ready. It is coming out of the lab, so users would have to do some tweaking,” he cautions, before offering to help anyone interested in adopting the research.
Mohanarajah cites Robohow as another project carrying on similar research. Robohow is coordinated by the Institute for Artificial Intelligence at the University of Bremen, Germany. As with RoboEarth, Robohow is funded by the European Commission as part of the Cognitive Systems and Robotics Initiative in the Seventh Framework Program.
	The Robohow website describes it as a four-year project that started in February 2012. The goal is to enable robots to competently perform everyday human-scale activities in human working and living environments. To achieve this goal, Robohow pursues a knowledge-enabled and plan-based approach to robot programming and control.
	With Robohow, humans may not be the only ones using YouTube videos to learn how to accomplish tasks. The project seeks to allow robots to turn to the Web for instructions on common tasks such as cooking. The program’s website includes videos of robots flipping pancakes, which requires carefully mapping out the individual movements. Written instructions on the Web lack details that are intuitive for humans, but not for robots. Video demonstrations may allow robotic systems to fill in knowledge gaps.
	In the United States, the National Science Foundation (NSF) is funding research by the Worcester Polytechnic Institute, Worcester, Massachusetts, and the Georgia Institute of Technology, Atlanta. “Traditionally what happens with a robot is that you will program the behavior that you want. The trouble is that anytime a robot gets into a new situation, you need a new behavior,” explains Satyandra Gupta, NSF program director, Robust Intelligence Program and National Robotics Initiative. “And most of the time, users of the robot are not going to be programmers, so they will not be able to program new behaviors.”
	He adds that the Internet can be a powerful tool for robotic systems. “Once a robot is connected to the Internet, a few different things happen. Number one, you get a complete connection to other robots, so they can communicate. They can do a Google search. They can get map information. There’s lots of information they can access. The second thing is that if they need to do heavy-duty computation, they don’t have to be limited by the brain, the central processing unit.”
	The Learning from Demonstration for Cloud Robotics project seeks to use both crowdsourcing and cloud computing to allow robots to learn household tasks from remotely located humans. “The idea of this particular project is that if robots need a new behavior, people on the Internet can demonstrate by tele-operating the robot and showing how the robot can do the task. By this demonstration, the robot can learn what the behavior should be, and the next time it encounters the same situation, it can use the behavior,” Gupta states. “A combination of crowdsourcing and cloud computing enables anybody in the whole world to participate in teaching the robot new behaviors.”
	Both Gupta and Mohanarajah agree cloud robotics research may someday benefit a wide range of systems performing an array of tasks, including potential military, homeland security or medical missions. But current research focuses on more practical tasks. “The reason our project uses household tasks is that there are lots of people out there who can teach the robot. There are not that many people who would have time to teach a robot to do, for example, a medical type of task,” Gupta points out.
	The NSF began funding the research in October 2013, and the universities have not yet reported on their progress. That report will be delivered at about the one-year mark, Gupta reveals. But he does foresee some challenges. For example, different people will perform the same task in different ways. Researchers will have to choose between right and wrong ways to perform a task, or they will need to consolidate information from multiple sources.
	Additionally, the interface for controlling the robots could be an issue. “In a household, if you have a specific task that requires very fine manipulation, you would need an interface that would allow people to do that task. Many tasks, such as chopping vegetables, require fine motion skills,” he offers.
	The NSF project is part of the National Robotics Initiative, a multi-agency investment in next-generation robotics research. The NSF has funded 30 new projects and invested $31 million under the initiative.
	Gupta adds that cloud computing could have a huge influence on the future of robotics. “Traditionally the problem that robots have had is that they had limited computing power, so that meant that whatever had been programmed was all they could do. That would make robots behave not in an intelligent way,” Gupta says.</text>
  <imgalttext>
    <img>Researchers working on the RoboEarth project demonstrate a robot’s ability to learn and cooperate with other robotic systems to serve medical patients. The project uses cloud computing to teach robots to perform tasks that seem intuitive for humans but are a challenge for robots.</img>
    <img>Simon the robot was developed by Georgia Tech researcher Andrea Thomaz, whose research is funded by National Science Foundation. Researchers foresee a future where any or nonprogrammer could buy a robot, take it home and instruct it to perform common tasks, such as clearing the dinner table.</img>
  </imgalttext>
</article>
