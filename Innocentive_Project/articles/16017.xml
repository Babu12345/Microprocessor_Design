<article>
  <type>article</type>
  <title>Commanding the Future Mission</title>
  <author>George I. Seffers</author>
  <date>May 1, 2016</date>
  <departments>
    <department>Technology</department>
  </departments>
  <tags>
    <tag>Army</tag>
  </tags>
  <abstract>U.S. Army researchers endeavor to develop a package of decision-supporting applications known as the Commander’s Virtual Staff and a Tactical Computing Environment that offers advanced computer-human interfaces, a collaborative data environment, intelligent mobility and a common user experience across computing platforms.</abstract>
  <text>U.S. Army researchers endeavor to develop a package of decision-supporting applications known as the Commander’s Virtual Staff and a Tactical Computing Environment that offers advanced computer-human interfaces, a collaborative data environment, intelligent mobility and a common user experience across computing platforms. 

The Army’s goal is to enable an expeditionary force capable of deploying at a moment’s notice to austere locations around the world with troops that can carry out their missions immediately upon arrival. Commanders and their staffs will need to efficiently plan, execute and assess multiple missions involving multiple types of threats, and they will have to constantly switch between different decision contexts in a fast-paced environment, explains Nick Palmer, lead computer scientist within the Mission Command Capabilities Division of the Army’s Communications-Electronics Research, Development and Engineering Center (CERDEC). That is why Palmer and his team in the Command, Power and Integration Directorate are developing the Commander’s Virtual Staff (CVS), which blends cognitive computing, artificial intelligence and computer automation to support tactical decision making for Army commanders and their staffs. 

Think of a hybrid of Siri, IBM’s Watson and Google Now designed for battle command purposes. “With the CVS, we’re trying to help with that cognitive burden by providing flexible decision-support tools and automation for specific tasks,” Palmer adds. 

The CVS science and technology project kicked off this year. Researchers, who have made significant progress in providing data to commanders, now are focused on transforming that data into usable information and knowledge as well as providing decision-aiding tools.

Studies conducted at the Mission Command Center of Excellence at Fort Leavenworth, Kansas, show that Army battalion commanders are unhappy with the volumes of data they must process and the number of systems they must consult to make decisions. To achieve situational understanding, commanders must interact with a large number of support staff members and examine different computer systems, all while they fuse large data sets to make informed decisions. 

The CVS project will provide computer automation targeted to commanders and their close staff members by exploring commercial technologies and advances in artificial intelligence that offer users proactive suggestions, advanced analytics and natural interaction tailored to their unique needs and preferences. CERDEC officials are considering some different approaches to artificial intelligence, some of which have been developed under other projects or programs. 

“We’re not trying to automate any decisions. We’re trying to automate the processing and alerting so that commanders are aware that decisions need to be made, and information is processed and made available to them so that they can make those decisions faster,” Palmer says. “Really what we’re trying to do is automate the things computers do well and leave the complex tasks to the humans so that they can spend more time visualizing, understanding and making decisions.”

The effort includes developing capabilities to more efficiently share information. For example, the operations and intelligence warfighting functions must collaborate closely, but because of classification levels, that often involves printing and hand delivering information between the two groups. “There’s a need to share required information across warfighting functions, but without requiring direct soldier engagement—having it happen behind the scenes and [automating] estimates and risk assessments based on the current plan, what’s happening in the field [and] how that plan is actually unfolding, and monitoring and alerting the commander when decisions need to be made,” Palmer says.

The first step for researchers is to determine which tasks can and should be automated. “We’re starting with a collaboration with the Mission Command Battle Lab, breaking down all of the tasks that are done across the staff in mission command, from the highest level … all the way down to individual tasks and subtasks, so that we can identify which of those could benefit best from some form of computer automation or simulation to support decision making,” Palmer states.

The CERDEC team has completed the first draft of the analysis and expects to release the second draft this month. “We’re starting first with the tasks that can benefit from simulation, mainly course-of-action development and analysis, and then we’re continuing the second phase of that task analysis to see which ones can benefit from automation technology. The third phase will be two validation events with soldiers at the Mission Command Battle Lab,” Palmer reports, adding that the first will be held this month to validate the analysis, and the second will be held in November to validate the solution concept. He and his team are working with the mission command project manager to evaluate technologies and potential plans for development and acquisition.

The Army also is developing a Tactical Computing Environment (TCE) across platforms, whether mounted, dismounted or fixed. TCE supports the Army's Command Post Computing Environment, which is being led by the Program Executive Officer for Command, Control and Communications-Tactical. "Right now, when a soldier is in the field, he has one piece of equipment in a Humvee; he has a different piece of equipment on foot; and when he’s in the command post, he has something else. All three have a different look and require different training,” states Cyndi Carpenter, chief of the CERDEC Mission Command Capabilities Division, Data Engineering Branch. “What we’re trying to do with TCE is to get that same look and feel on all three or more products that he has to use so that there’s less training time, and he’s seeing the same thing in every aspect of where he is. It makes it easier for him to switch back and forth.”

Alex O’Ree, a computer scientist within CERDEC’s Command, Power and Integration Directorate, explains the challenges. “The devices all have different capabilities—some have touchscreens and some don’t,” O’Ree points out. 

Furthermore, when warfighters in Humvees or armored vehicles are on the move across tough terrain, possibly dodging enemy attacks, hitting the right button on a touchscreen or keyboard poses problems. Therefore, Army officials envision combat computer systems that recognize gestures or use eye tracking. Researchers also are working on a voice recognition app capable of operating in places Siri would not dare. “You want to say what you need to see instead of hunting and pecking through a bunch of different menus or pressing keys on a keyboard. In theory, this actually helps enable using a computer system while you’re on the move,” O’Ree says.

The researchers acknowledge, however, that a combat environment is formidable for a voice recognition system. Envision a command center with multiple conversations happening both in the room and across a number of radios. The background noise can be mitigated within vehicles equipped with an intercom system that allows warfighters to communicate through microphones mounted on their helmets, O’Ree observes. “As a research and development effort, we were able to integrate those same microphones, which are custom-tailored for noisy environments. We’ve had a lot of success in this particular area,” he says.

The TCE also will include a collaborative data environment. “A lot of the currently fielded digital mission command systems enable users to collaborate directly with other users on the network. They don’t have to be in the same location. They can be on the other side of the planet,” O’Ree states. “We’re trying to extend and augment some of those capabilities to bring them down into new areas, such as to the handheld and dismounted area. We’re effectively trying to maintain a level of collaboration the commanders are used to in the command post when they’re outside the command post.” He adds that network constraints and limited connectivity pose additional challenges.

The TCE also will feature an intelligent mobility capability, offering situational awareness of the network. “We’re trying to perform research and development into areas that would enable applications, such as something that works on a smartphone or a desktop or anything else, to intelligently know the network conditions. Maybe we have network connectivity to the battle captain or the senior noncommissioned officer, but we might have no connectivity or just poor connectivity to somebody else,” O’Ree elaborates. “If you’re on a highly iffy network, we probably don’t want to enable video conferencing because the network can’t support it right now.”

The TCE is part of a science and technology objective called Expeditionary Mission Command that will conclude with a 2018 demonstration. Soldiers with the 1st Infantry Division, Fort Riley, Kansas, were allowed to explore the TCE’s capabilities last summer, and the system will be included in a field-based risk reduction effort this summer at Fort Dix, New Jersey.

Both the CVS and the TCE are follow-on efforts to the recently completed Mission Command/Actionable Intelligence Technology-Enabled Capability Demonstration (MC/AI TECD). The effort is described on an Army website as a demonstration of “a system of game-changing capabilities for company-level units and below.” The goal, according to the website, is to “prevent surprise encounters and help small units achieve tactical overmatch without increased physical or cognitive burden on the soldier.”

The MC/AI TECD effort completed its final demonstration last year at Fort Dix. The program developed a variety of technologies and capabilities in three major areas: proactive decision support and collaboration; situational awareness and understanding; and faster and more accurate target identification and handoff. Some of the systems have transitioned to programs of record, including a tactical Twitter-type system known as TacticalPost, which is now part of the Nett Warrior program. 

Technologies developed under the MC/AI TECD program and its two follow-on efforts have one common element. “All the capabilities we’re developing have to be expeditionary so that the commanders will be able to execute and command from any location,” Palmer says.</text>
  <imgalttext>
    <img>Soldiers attack simulated enemy combatants during a training exercise in Germany. Army researchers are integrating voice recognition into computing systems mounted onto vehicles with intercoms that allow soldiers to communicate in combat conditions.</img>
    <img>U.S. Army soldiers engage targets during a live-fire exercise in Lithuania. The Tactical Computing Environment program seeks to provide warfighters with an unprecedented degree of situational awareness, essentially eliminating battlefield surprises.</img>
  </imgalttext>
</article>
