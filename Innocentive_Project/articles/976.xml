<article>
  <type>article</type>
  <title>Common Ground Program Sets Sail</title>
  <author>Henry S. Kenyon</author>
  <date>June 2005</date>
  <departments>
  </departments>
  <tags>
    <tag>Military</tag>
    <tag>June 2005</tag>
  </tags>
  <abstract>The U.S. Navy is on the verge of deploying the first parts of an intelligence collection and management network designed to share data between fleet task forces and command and analysis centers. The completed system will provide intelligence, surveillance, reconnaissance and targeting support to government agencies, U.S. allies and all of the services. </abstract>
  <text>   The U.S. Navy’s Distributed Common Ground System (DCGS-N) will allow fleet operating units to share and disseminate intelligence data from a variety of sources. The DCGS-N features data fusion technologies and automated workflow processes to cue and prompt users about incoming information. A common backbone links all of the services’ DCGS systems, permitting joint operations and enhanced situational awareness.processes to cue and prompt users about incoming information. A common backbone links all of the services’ DCGS systems, permitting joint operations and enhanced situational awareness.Service revamps how it processes and exploits information.The U.S. Navy is on the verge of deploying the first parts of an intelligence collection and management network designed to share data between fleet task forces and command and analysis centers. The completed system will provide intelligence, surveillance, reconnaissance and targeting support to government agencies, U.S. allies and all of the services. Part of a larger U.S. Defense Department effort, the Distributed Common Ground System–Navy (DCGS-N) will create a common framework and architecture for sharing and disseminating intelligence data. It will operate within the Navy’s FORCEnet structure and serve both tactical- and national-level operational requirements by standardizing how the service processes and exploits information from a variety of sources such as sensor feeds, imagery and reports from ground forces including U.S. Marine Corps units. This incoming data will range from raw to fully analyzed material, explains Lorraine M. Wilson, direct reporting program manager to the assistant secretary of the Navy for research, development and acquisition for the Navy DCGS, Chantilly, Virginia. The first deliveries of DCGS-N-related systems are scheduled for 2007. Initial versions will support intelligence preparation of the battlespace for strike and fires missions by processing data from tactical sensors and platforms such as U-2 reconnaissance aircraft, Global Hawk unmanned aerial vehicles and satellite-based systems. DCGS-N terminals, processing equipment and servers will be integrated into the command and control assets of Navy ships, allowing users to access intelligence databases. Wilson explains that the system will be very robust from the outset, noting that the program could have delivered a product of spiral development that processed imagery for specific missions only, such as strike warfare. Instead, it will support a variety of missions such as signals and communications intelligence, intelligence preparation of the battlespace, special operations and precision-guided engagement. In later spirals, the DCGS-N will expand to provide antisubmarine-warfare and human-intelligence-gathering data. Wilson notes that the next iteration will integrate with the aerial common sensor, allowing DCGS-N groundstations to process data feeds from those sensor systems. All of the services will use the DCGS. A major component for this joint interoperability is the DCGS integration backbone (DIB), which will allow Navy units to communicate with each other and the other service’s DCGS systems. Primarily a software-based system with some related hardware such as servers and workstations, the DIB is designed around an open programming architecture. This structure will permit new applications to be easily added and will allow it to operate with other systems.But the Navy must address a networking issue to fully realize its interoperability goals. Wilson notes that the service does not have an existing enterprise architecture that permits users to simply plug in new applications. She adds that efforts such as the Global Information Grid and the Network Centric Enterprise Services program are important because they will establish the servicewide enterprise in which applications like the DCGS-N will operate. The DCGS-N and the Global Command and Control System (GCCS) also are among the first Navy systems to rely on an open network. “In the future there will be a services enterprise, and you will just bring your software. But being one of the first systems out there, we have to bring this to the table. We will all have to make sure that we converge on many of these common enterprise services and backbones,” she says. Managing the system’s data fusion capabilities is an ongoing challenge for the program. Other concerns include data tagging and storage for future retrieval. Describing these issues as housekeeping concerns, she adds, “If you don’t have housekeeping, you don’t have a system.”For example, the GCCS currently performs a variety of functions within the fleet such as command and control; track management; and intelligence, surveillance and reconnaissance applications. Other systems also rely on intelligence data, but this arrangement is inefficient, Wilson maintains. In the future, certain systems will be designated as the primary repositories for specific data. The DCGS-N will hold imagery, while GCCS collects all tracking management information. “We said, ‘You own this data, and we won’t reproduce it. When we need that data, we’ll point to you,’” she says.But Wilson adds that some units and systems may have their own local data caches to provide real-time data across a local area network (LAN); however, that data will originate from an authoritative parent database. “This is a fairly simple concept, but it’s never really been done this way before. Because we’re going to a common enterprise, the doors are now open to do that kind of thing,” she observes. User interface design, workflow and data usage present additional considerations. The DIB architecture features workflow functions that allow the services to design operational rules for personnel using the system. Wilson notes that the program office holds regular meetings with fleet stakeholders to plan all of the processes for individual mission and job profiles. For example, developers map out all of the steps required to perform an analyst’s job such as making telephone calls, inputting data into the LAN and then moving to another terminal to access more information. The goal of these studies is to replace this inefficient activity with a single multifunction workstation allowing users to search and mine data and send it across the chain of command. “If you are an imagery or strike analyst, or an officer who’s managing that space, each profile will have a different set of workflows automating most of the job’s manual aspects, directing you to a database and cueing you when new data is available,” she explains. The new workstations will be flexible enough to compensate for new and unexpected operations and job requirements while performing data discovery functions. Wilson notes that analysts’ job functions are well defined and can be formatted into workflows. “Every DIB has to be populated with workflows and metadata to be of use to the service. That’s what we’re doing this year and testing out next year,” she says. As a cost-saving measure, the U.S. Air Force—the executive agent for the DIB deployment—will procure the systems for all the services. The Navy received eight of the Raytheon-manufactured DIBs in the spring of 2005, but Wilson adds that because of production schedules, the designated ships will not be ready until 2007.  The DCGS-N is designed to serve across several echelons, or tiers, in the Navy. Tier 1 capabilities are shore- or command-ship-based systems serving as reach-back nodes for theater operations. Units fielding Tier 2 systems include carrier, strike and expeditionary task forces, with the main nodes installed on aircraft carriers and large-deck amphibious ships. Wilson explains that this is the dominant fielding of the system that will include up to 24 units.The final category is Tier 3, which is tailored for individual ships. Future warships, such as the DDX, littoral combat ships and nuclear-powered guided-missile submarines may operate Tier 3 DCGS-N nodes. Wilson adds that only the DDX design is currently validated for this application. Featuring a minimal footprint, most Tier 3 vessels will not have onboard imagery operators because they will receive processed data only. But all Tier 3 vessels will be connected to higher echelon systems via the DIB. “Those unit-level ships are going to have organic Navy sensors on them. We want to be able to take advantage of those sensors to pump intelligence data back into the enterprise,” she says. Although the DCGS is designed for interoperability, additional systems engineering is necessary to make this possible. Wilson explains that the services must first integrate the DIBs into their systems to establish enterprise architectures before they can be united into a Defense Department-wide network. “You have four services developing their own enterprises but using a common backbone so that interoperability is definitely feasible. But it’s not designed yet,” she maintains.Wilson concedes that the Office of the Secretary of Defense is only beginning to fund efforts to promote joint interoperability. Yet even without such programs, the services’ DCGS systems already interoperate at a basic level because they share the same backbone. “But to really get the big bang for the buck to do warfighting, you need a joint concept of operations and you need the doctrine, tactics, techniques and procedures to go with it. A lot of that will drive the engineering and architectural design of the joint enterprise. That’s work that has to be done because the DIB was mandated and all the services jumped onboard. But now we have to grow the rest of the service infrastructure to take advantage of it,” she shares. A major challenge remains: fitting existing systems into the new architecture and managing the inherent uncertainty of the process. Wilson notes that the goal of the program’s initial spiral is moving legacy capabilities into the new system. “The good news about existing capability is that it’s tried and true—you know it works. The bad news is it’s based on an existing design, and you have to somehow morph that into this enterprise environment,” she says. But Wilson is sanguine about the state of the program. She notes that risk reduction efforts have been underway for more than a year involving a series of engineering integrated product teams studying commercial products similar to those expected to operate in the DIB. The program also is paying close attention to workflows. Wilson describes these as the heart of how the DIB and the DCGS will use data. While the system will provide users with data, if automated applications are not installed, operators will be saturated with too much information. She adds that the program currently is working closely with Navy stakeholders to determine how they want data used in particular jobs and is inserting those suggestions into the design. Web ResourcesDistributed Common Ground System–Navy: www.hq.navy.mil/rda/drpmdcgsn.aspNorthrop Grumman Capitol Source: Distributed Common Ground System–Navy: www.capitol.northgrum.com/programs/dcgsn.htmlDistributed Common Ground System: www.globalsecurity.org/intell/systems/dcgs.htm </text>
  <imgalttext>
  </imgalttext>
</article>
