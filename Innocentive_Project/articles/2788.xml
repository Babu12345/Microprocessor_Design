<article>
  <type>article</type>
  <title>New Chips on the Block</title>
  <author>Rita Boland, SIGNAL Magazine</author>
  <date>November 2011</date>
  <departments>
  </departments>
  <tags>
    <tag>Computing</tag>
    <tag>Featured Stories</tag>
    <tag>November 2011</tag>
  </tags>
  <abstract>The future of computing is being shaped by breakthroughs in many facets of the industry, but no matter the devices or the Internet services they access, all will be influenced by the computer chip. Innovations in this area will help drive advancements in others, and big names in the field are hard at work to enable emerging capabilities. </abstract>
  <text> Intel Lab’s experimental single-chip cloud computer is a 48-core concept microprocessor that is like a microcosm of a cloud data center. The architecture could offer a solution to some of the issues chip developers face. These tiny technologies will influence what systems can accomplish in the years to come. The future of computing is being shaped by breakthroughs in many facets of the industry, but no matter the devices or the Internet services they access, all will be influenced by the computer chip. Innovations in this area will help drive advancements in others, and big names in the field are hard at work to enable emerging capabilities. Intel Corporation, a well-known leader in computer-chip technology, is conducting basic research to ensure improvements in performance. “We set a target for ourselves to achieve a milestone of teraflops of computing power on terabytes of memory,” explains Jim Held, director, Tera-Scale Computing Research, Intel, and an Intel fellow at Intel Labs. He explains that Intel officials decided they needed to determine how to scale performance in the face of limiting factors such as transistors, generators and power density so they could continue to enable programmers to perform more functions. A major barrier to scaling performance is energy efficiency. Held says that developers have reached a point where they no longer can improve performance using the current amount of power per transistor. Instead, these devices will have to become more efficient, or computing platforms will heat up to extreme levels. “Especially in mobile ... people want things that don’t get too hot or use up battery power too quickly,” he explains. Even with server centers and cloud computing, energy efficiency matters because it costs to power those technologies, and it costs to cool down locations dealing with residual heat. Chip developers also must figure out how to realize these efficiencies without continually increasing design complexity. “The costs of building the processors cannot increase as fast as we’d like performance to increase or they will become uneconomical,” Held states. Intel is working to address the problem through parallelism in which processors work together. Generally this is done with multicore processors. Held compares parallel computing to a human work environment. Employees can perform faster only to a certain point before additional personnel are necessary. To ensure success, all the people must function well together without requiring so much communication among themselves that they slow each other down. In the same way, processors must interact without losing speed. Another major challenge for Intel is identifying and fostering emerging applications that will take advantage of—and be enabled by—advances. One effort aims to combine and integrate more parts of systems over their life cycle to create simpler devices and new form factors that offer benefits such as lower costs. Computing continues to move to new platforms such as tablets and smartphones, so the company is working to match their offerings to what people want to do with these tools.Held explains that Intel has processors for general computing and specialized processors. Early this year, Intel introduced its 2nd Generation Intel Core processors—code-named Sandy Bridge—that integrate co-processors particularly suited to graphics. Held believes that graphics have become so important in all types of computing that it was a natural choice to make them part of a processor. Sandy Bridge also features integrated tools for processing multimedia and building blocks that will allow very efficient processing types. This addition is important, as consumers increasingly want access to video content, including high-definition video. Demand for that is expected to increase over time, according to leaders across the computing industry. Held says that whenever Intel identifies a functionality that is used frequently and amenable to implementation, it adds it to its processors. Moving forward, specialized processors will continue to enable new capabilities such as encryption and media acceleration. Researchers at Intel also recently have demonstrated cameras and video displays interacting together. Dubbed the Magic Mirror by developers, it creates realistic avatar forms of users. All the shaping of the virtual people is done by a natural user interface in which human movements, rather than controllers, are read by the system. Motions are captured as well, so people can see their avatars in different positions or making movements. The avatar is overlaid on a video display. Developers say this will lead to virtual shopping where people can see what clothes will look like on their bodies based on how they appear on the avatar. Held explains that visual computing also will grow in demand so Intel works closely with app developers to understand what they hope to enable. Intel’s strategy for remaining on the leading edge involves obtaining technology prototypes to analyze and experiment with so the company can determine what plans it must alter to ensure its products can support system goals. Intel has established a feedback loop with the development base it supports: The company reaches out to program and application developers around the industry to learn what they need, and in its research laboratories, experts try to figure out what to build to inspire and stretch the ideas of developers so they can attain what is not yet feasible. Whenever his organization identifies capabilities it cannot yet achieve, “We take it as a challenge,” Held states. “There are things we can’t do yet, and developers are very good at living within what they see we can do right now,” he explains. “I think the challenge ... is getting them to think about what will soon be possible rather than confining them to today.” One technology that could change what researchers design is the experimental single-chip cloud computer (SCC) created by Intel Labs. Already, dozens of research institutions around the world are using it to explore future software possibilities. The SCC is a 48-core concept microprocessor that incorporates technologies intended to scale multicore processors to 100 cores and beyond. It also is partly a microcosm of a cloud data center. Each core can run a separate operating system and software stack and can act like an individual node that communicates with other nodes over a packet-based network. The architecture could help meet some of the challenges Held outlines; it features innovations for scalability in terms of energy efficiency, including improved core-core communication and techniques that enable software to configure voltage and frequency dynamically to attain power consumptions from 25 to 125 watts. Held says Intel Labs is gratified by the number of responses it has received to the product and the continued enthusiasm of users, calling the SCC a new adventure that is turning out very well. “It shows how we don’t exist in isolation or create things without feedback,” he shares. Though the SCC has the potential to make big changes in the computing industry, Held notes that game-changing technology is in the eye of the beholder. However, he says he is looking forward to the emergence of certain technologies. “I’m particularly excited about the decision of our Data Center Group to start a family of high-performance parallel computer processors,” he explains. That project will advance into the teraflop level of performance that will enable fundamentally different capabilities and bring general-purpose computing to a higher level of performance in a single processor. Held also is eager for advances in situational analysis, finance and energy exploration once those fields can take advantage of teraflop performance in the multicore systems. In addition to technology development, Intel also is focusing on company development and considering how to remain at the top of its industry. Held says one challenge is determining how to apply Intel’s expertise and its processor technologies to establish the company in the growing segment of lightweight mobile devices. He explains that Intel’s products soon will begin to appear in those spaces, but personnel are working on how to extend offerings to any computing device in a competitive and top-notch manner. The effort involves tradeoffs between efficiency and performance. Building energy efficient processors for smartphones and tablets is different than designing them for traditional desktop and laptop computers. Mobility and the cloud have caused major changes in the attention of all information technology research, Held says. Intel’s research spans more than simply multiprocessor cores; it examines many technologies that interconnect in systems through them. “Delivering performance requires you to address all of those,” Held explains. “Any one can become a bottleneck.” Over at IBM, researchers are taking computer chips in a different direction by developing experimental chips designed to emulate the brain’s ability for perception, action and cognition. Personnel involved with the project believe they could yield orders of magnitude less power consumption and space than today’s computers. According to the company, these neurosynaptic computing chips re-create the phenomena between spiking neurons and synapses in biological systems, such as the brain, through advanced algorithms and silicon circuitry. Two prototype chips already have been fabricated and currently are undergoing testing. Computer system developers who employ these chips will program machines in new ways, creating computers that will learn through experiences, find correlations, create hypotheses, remember and learn from results. The work is performed under the Defense Advanced Research Projects Agency-sponsored Systems of Neuromorphic Adaptive Plastic Scalable Electronics, or SyNAPSE, project. Phases zero and one are complete; IBM and its partners in academia recently received $21 million from the agency for Phase 2. The goal is to create a system that can both analyze complex information from sensory modalities at once and dynamically rewire itself as it interacts with its environment. An official with IBM says that in the future, computers increasingly will need to understand complex interrelationships, correlations and unstructured information streaming from multiple sources at once. The traditional von Neumann architecture—on which most computers are based—is not suited to make sense of these types of problems efficiently. The official adds that these cognitive computing prototype chips mark a total departure from traditional chips and will require people to revolutionize their concepts of how computers operate.Unlike traditional computers, which must be hard-wired and programmed for every action, the cognitive computing chips can sense and trigger actions based on their environments and have no set programming. They also are highly parallel rather than sequential. These chips are event-driven, resulting in greater power efficiency; can compute what they need, when they need; and have no clock, per se. They also lack a bus or cache because memory and processor are integrated into one. In addition, the chips are reconfigurable and fault tolerant by default—“just like how you can lose some brain cells and still recognize your mother’s face in a crowd,” the official states. IBM has identified several applications for the chips, though project personnel believe they have the capability to transform almost every industry. Examples put forth by the company include gloves for grocers that could identify bad produce; smart cameras at traffic lights that can detect abnormal scenarios, alert appropriate authorities and redirect traffic; and cognitive computers that find large-scale and complex patterns in financial markets.WEB RESOURCESIntel Tera-Scale Computing Research: http://techresearch.intel.com/ResearchAreaDetails.aspx?Id=27Single-Chip Cloud Computer: http://techresearch.intel.com/ProjectDetails.aspx?Id=1Sandy Bridge: http://software.intel.com/en-us/articles/sandy-bridgeSyNAPSE: www.ibm.com/smarterplanet/us/en/business_analytics/article/cognitive_computing.htmlJoin the Discussion!Do you have ideas about the future of the Internet and computing? Do you foresee the role your company will play? Share your insights on SIGNAL Scape: www.afcea.org/signal/signalscape/?p=14218 </text>
  <imgalttext>
  </imgalttext>
</article>
